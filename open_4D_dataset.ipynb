{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd4b2de-1199-4037-9612-f76cf4433f40",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#import py4DSTEM\n",
    "import math\n",
    "import os\n",
    "# import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from pyxem.utils.io_utils import _parse_hdr\n",
    "import h5py\n",
    "import hyperspy.api as hs\n",
    "from converter_nord import save_signal\n",
    "import pyxem as pxm\n",
    "%matplotlib qt\n",
    "#%matplotlib inline\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d62765",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Folders settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9d0328",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# To set Hyperspy preferences with the interface\n",
    "#hs.preferences.gui()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1611398",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Choose root_dir depending on the computer (local, WS, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa23a2a2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# config_file = 'configs/config_federico.yml'\n",
    "config_file = './configs/config_gulnaz_new_dataset.yml'\n",
    "os.chdir('.')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff4dd9c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87492a33",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load config file\n",
    "import os\n",
    "import yaml\n",
    "from yacs.config import CfgNode as CN\n",
    "\n",
    "\n",
    "with open(config_file, \"r\") as stream:\n",
    "    try:\n",
    "        cfg = yaml.safe_load(stream)\n",
    "\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "cfg = CN(cfg)\n",
    "# cfg.SETUP.DATA_PATH = root_dir+ cfg.SETUP.DATA_PATH\n",
    "# cfg.SETUP.CALIB_DATA_PATH = root_dir+ cfg.SETUP.CALIB_DATA_PATH\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0811e421",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load Data in a \"Electron Diffraction\" 2D Signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e54ff8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Diffraction pattern calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf87a1e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# To calibrate, set the PATTERN_CALIBRATED parameter to False\n",
    "if cfg.SETUP.PATTERN_CALIBRATED:\n",
    "    roi_calib = hs.roi.CircleROI(cx=cfg.SETUP.CAlIB_COOR[0],cy=cfg.SETUP.CAlIB_COOR[1],r=cfg.SETUP.CAlIB_COOR[2])\n",
    "else:\n",
    "    dp = pxm.load_mib(cfg.SETUP.CALIB_DATA_PATH)\n",
    "    dp.set_signal_type('electron_diffraction')\n",
    "    dp.compute()\n",
    "    dp_selected = dp.inav[dp.axes_manager.indices]\n",
    "    dp_selected.plot()\n",
    "    roi_calib = hs.roi.CircleROI(cx=130,cy=130,r=30)\n",
    "    # set the line ROI on the interactive plot\n",
    "    # connect the roi with the plot\n",
    "    roi_calib.interactive(dp_selected, color=\"red\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26411b95-86f7-4242-a42f-8394d4fa71e6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Fine tune the roi values\n",
    "roi_calib.gui()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396a220e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Once the ROI is selected, print the values and copy to the yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaf8035",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if cfg.SETUP.PATTERN_CALIBRATED:\n",
    "    print(f\"These are the calibration values: [cx, cy, r]: [{roi_calib.cx}, {roi_calib.cy}, {roi_calib.r:.2f}]\")\n",
    "else:\n",
    "    print(f\"Values to paste in the Yaml file CALIB_COOR: [cx, cy, r]: [{roi_calib.cx}, {roi_calib.cy}, {roi_calib.r:.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2ae79a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loading dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d7096f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567e4f92",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_path = Path(cfg.SETUP.DATA_PATH)\n",
    "if dataset_path.suffix == \".mib\":\n",
    "    dp = pxm.load_mib(cfg.SETUP.DATA_PATH)\n",
    "    _parse_hdr(cfg.SETUP.DATA_PATH)\n",
    "    dp.set_signal_type('electron_diffraction')\n",
    "    dp.metadata\n",
    "    dp.compute() # This object is a lazy signal, so before plotting we need to compute the object\n",
    "    # # convert signal to the right shape\n",
    "    dp = hs.signals.Signal2D(dp.data.reshape(cfg.SETUP.DATA_SHAPE[0],cfg.SETUP.DATA_SHAPE[1],256,256))\n",
    "    dp.data.shape\n",
    "else:\n",
    "    dp = hs.load(cfg.SETUP.DATA_PATH, lazy=True)\n",
    "\n",
    "dp.set_signal_type('electron_diffraction')\n",
    "dp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aa4294",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: use if to open file according to the file extension\n",
    "#dp = pxm.load_mib(cfg.SETUP.DATA_PATH)\n",
    "# dp = hs.load(cfg.SETUP.DATA_PATH, lazy=True)\n",
    "#dp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77572f8a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#dp.axes_manager #.gui()\n",
    "#hs.print_known_signal_types()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118a75a7",
   "metadata": {},
   "source": [
    "### Crop dataset (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa5b6cf-fc42-45e5-957a-f1e984206359",
   "metadata": {},
   "source": [
    "choose the crop region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed535268",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_roi = hs.roi.RectangularROI(left=50, top=60, right=90, bottom=100)\n",
    "dp.plot()\n",
    "crop_roi.add_widget(dp, axes=dp.axes_manager.signal_axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868a8763-e47b-4a3a-938d-c909311e345d",
   "metadata": {},
   "source": [
    "once happy with region, do the crop and plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba67c6af-e988-427d-b4f6-051dab25cc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = crop_roi(dp, axes=dp.axes_manager.signal_axes)\n",
    "crop.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c0053c-fb63-4983-bd39-774b374d0322",
   "metadata": {},
   "source": [
    "to save the file, it takes a few minutes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5e4357-073f-408c-a664-e9f92ded12a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop.save(\"croped.zspy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a79d0e-5d07-4e6c-bb19-d8c83cf48907",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = hs.load(\"croped.zspy\", lazy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2220a20b-feb4-4c9a-a81f-7268089825a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1743c8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Conversion to the right shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7963c6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Reshape dp to (257,256 | 256,256)\n",
    "# im = hs.signals.Signal2D(dp.data.reshape(256,257,256,256))\n",
    "#im = hs.signals.Signal2D(dp.data.reshape(cfg.SETUP.DATA_SHAPE[0],cfg.SETUP.DATA_SHAPE[1],256,256))\n",
    "#im.data.shape\n",
    "#im.set_signal_type('electron_diffraction')\n",
    "#im.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872f91ee-6416-4e95-9d91-59d7da28fc07",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "(Use the + button to make the point selector bigger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd9ec99",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#im.axes_manager.gui_navigation_sliders()\n",
    "dp.axes_manager.indices = (130, 198)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cf9d3f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Virtual Diffraction Imaging & Selecting Regions\n",
    "## Interactive VDF Imaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84c5cc2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#displaying the DP from coordinates of the red point\n",
    "%matplotlib qt\n",
    "dp_selected = dp.inav[dp.axes_manager.indices]\n",
    "dp_selected.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc716bc9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# set the line ROI on the interactive plot\n",
    "roi_line = hs.roi.Line2DROI(x1= 21, y1=132, x2=200, y2=55)\n",
    "roi_line.interactive(dp_selected, color=\"yellow\") # connect the roi with the plot\n",
    "# with roi_calib.events.suppress():\n",
    "roi_calib.interactive(dp_selected, color='red')\n",
    "roi_calib.events = None\n",
    "#roi_line.gui()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f573bf1-186c-4444-aa01-8ba1ab0f961a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "roi_line.gui()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4371de13-a36f-43e2-9685-7780577d0368",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4778d539",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_angles(coordinates):\n",
    "    # calculate distance in pixels from roi center to the center of the line \n",
    "    dist_pix = math.sqrt((coordinates[0][0] - coordinates[1][0])**2 + (coordinates[0][1] - coordinates[1][1])**2)\n",
    "    # convert semiangle from mrad to degrees\n",
    "    semiangle_in_deg = math.degrees( cfg.SETUP.SEMIANGLE/1000.0) \n",
    "    deg2pix_ratio = semiangle_in_deg/(roi_calib.r)\n",
    "    dist_deg = dist_pix * deg2pix_ratio\n",
    "    return (-dist_deg, 0, dist_deg) \n",
    "\n",
    "def get_list_of_lines(p1,p2,n_lines, line_widths):\n",
    "    #calculation of coordinates\n",
    "    angle = math.atan((p2[1] - p1[1]) / (p2[0] - p1[0]))\n",
    "    lengths = [i * (roi_line.length / (n_lines-1)) for i in range(n_lines + 1)]  #split the line in equal lengths\n",
    "    #get list of coordinates\n",
    "    coordinates = [(np.cos(angle) * line_len + roi_line.x1,\n",
    "                    np.sin(angle) * line_len + roi_line.y1)\n",
    "                   for line_len in lengths]\n",
    "    coordinates = np.array(coordinates, dtype=np.int32)  #set coordinate values to int\n",
    "    # define multiple roi for lines (with different values of line width)\n",
    "    rois_line = [\n",
    "        hs.roi.Line2DROI(x1=coordinates[i][0], y1=coordinates[i][1], x2=coordinates[i][0], y2=coordinates[i][1],\n",
    "                         linewidth=line_width)\n",
    "        for line_width in line_widths\n",
    "        for i in range(len(coordinates) - 1)]\n",
    "\n",
    "    #getting metadata info label\n",
    "    meta_data = []\n",
    "    angles = calculate_angles(coordinates)\n",
    "    for line_width in line_widths:\n",
    "        for i in range(len(coordinates) - 1):\n",
    "            meta_data.append((\"Line\", coordinates[i][0], coordinates[i][1], line_width, angles[i]))\n",
    "    \n",
    "\n",
    "    return rois_line, meta_data\n",
    "\n",
    "def get_list_of_circles(p1, p2, n_circles, circles_radius):\n",
    "    #calculation of coordinates\n",
    "    angle = math.atan((p2[1] - p1[1]) / (p2[0] - p1[0]))\n",
    "    lengths = [i * (roi_line.length / (n_circles-1)) for i in range(n_circles+1)]  #split the line in equal lengths\n",
    "    #get list of coordinates\n",
    "    coordinates = [(np.cos(angle) * line_len + roi_line.x1,\n",
    "                    np.sin(angle) * line_len + roi_line.y1)\n",
    "                   for line_len in lengths]\n",
    "    coordinates = np.array(coordinates, dtype=np.int32)  #set coordinate values to int\n",
    "    # define multiple roi for lines (with different values of line width)\n",
    "    rois_circle = [\n",
    "        hs.roi.CircleROI(cx=coordinates[i][0], cy=coordinates[i][1],\n",
    "                         r=circle_radius)\n",
    "        for circle_radius in circles_radius\n",
    "        for i in range(len(coordinates) - 1)]\n",
    "    #meta data of each circle\n",
    "    angles = calculate_angles(coordinates)\n",
    "    meta_data = [\n",
    "        (\"Circle\", coordinates[i][0], coordinates[i][1], circle_radius,\n",
    "        angles[i]\n",
    "        )\n",
    "        for circle_radius in circles_radius\n",
    "        for i in range(len(coordinates) - 1)]\n",
    "    return rois_circle, meta_data\n",
    "\n",
    "\n",
    "roi_lines = get_list_of_lines(p1= (roi_line.x1, roi_line.y1), p2= (roi_line.x2, roi_line.y2),\n",
    "                          n_lines= cfg.ROI.N_LINES,\n",
    "                          line_widths= cfg.ROI.LINE_WIDTHS)\n",
    "\n",
    "roi_circles = get_list_of_circles(p1= (roi_line.x1, roi_line.y1), p2= (roi_line.x2, roi_line.y2),\n",
    "                                  n_circles=cfg.ROI.N_CIRCLES,\n",
    "                                  circles_radius= cfg.ROI.CIRCLES_RADIUS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3271f83",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## (Optional) - graph ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd6c729",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# close active plot before, in order to \"erase\" previous ROIs\n",
    "%matplotlib qt\n",
    "dp_selected.plot()\n",
    "for roi in roi_lines[0]:\n",
    "    roi.interactive(dp_selected, color=\"green\")\n",
    "for roi in roi_circles[0]:\n",
    "    roi.interactive(dp_selected, color=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46848749-5d5c-4759-8213-3f05df230bc1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Image stack of Integrated intensity on ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43a3ff4-95be-4097-b422-bad7cadbdbc5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def correct_pixels_and_normalize(img):\n",
    "\n",
    "    #bad pixel correction:\n",
    "    img = hs.signals.Signal2D(img)\n",
    "    img.set_signal_type('electron_diffraction')\n",
    "    s_dead_pixels = img.find_dead_pixels(lazy_result=True, show_progressbar=True)\n",
    "    s_hot_pixels = img.find_hot_pixels(show_progressbar=True, threshold_multiplier = cfg.SETUP.THRESHOLD_MULTUPLIER)\n",
    "    img_corrected = img.correct_bad_pixels(s_dead_pixels+s_hot_pixels, show_progressbar=True, inplace=False, lazy_result=True)\n",
    "\n",
    "    #normalization\n",
    "    img_normalized = np.array(img_corrected.data)\n",
    "    img_normalized = (img_normalized - np.min(img_normalized))/np.ptp(img_normalized)\n",
    "    img_normalized = hs.signals.Signal2D(img_normalized)\n",
    "    img_normalized.set_signal_type('electron_diffraction')\n",
    "    return img_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5b6cc0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vdfs_circles = []\n",
    "for roi in roi_circles[0]:\n",
    "    img = dp.get_integrated_intensity(roi).data.reshape(cfg.SETUP.DATA_SHAPE)\n",
    "    img = correct_pixels_and_normalize(img)\n",
    "    vdfs_circles.append(img)\n",
    "\n",
    "vdfs_lines = []\n",
    "for roi in roi_lines[0]:\n",
    "    img = dp.get_integrated_intensity(roi).data.reshape(cfg.SETUP.DATA_SHAPE)\n",
    "    img = correct_pixels_and_normalize(img)\n",
    "    vdfs_lines.append(img)\n",
    "\n",
    "vdf_stack = hs.stack( vdfs_lines + vdfs_circles, new_axis_name=\"ROI lines\", show_progressbar=True)\n",
    "\n",
    "vdf_stack.set_signal_type(\"virtual_dark_field\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0782b15",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### With the Qt pop-up interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09da3042",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for plotting outside jupyter\n",
    "%matplotlib qt\n",
    "# for plotting inside jupyter\n",
    "# %matplotlib inline\n",
    "# %matplotlib widget\n",
    "vdf_stack.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c0735b-b6e4-4976-80ad-a62b6e48fdf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "867289ab",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### With the inline interface of Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7696463",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create the list of labels\n",
    "meta_data = roi_lines[1] + roi_circles[1]\n",
    "labels = [f\"{data[0]} width={data[3]} angle={data[4]:.2f} deg\" if data[0] == \"Line\"\n",
    "          else \n",
    "          f\"{data[0]} radius={data[3]} angle={data[4]:.2f} deg\"\n",
    "          for data in meta_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd87f58d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize = cfg.SETUP.PLOT_SIZE)\n",
    "_ = hs.plot.plot_images(vdf_stack, per_row=3, axes_decor=\"off\", colorbar=False, label= labels, fig= fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f34d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdf_stack.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce486ed4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save images stack into a tiff file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0b7d5f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def increment_path(path, exist_ok=False, sep='', mkdir=False):\n",
    "# Increment file or directory path, i.e. runs/exp --> runs/exp{sep}2, runs/exp{sep}3, ... etc.\n",
    "#path = Path(path)  # os-agnostic\n",
    "#if path.exists() and not exist_ok:\n",
    "#    path, suffix = (path.with_suffix(''), path.suffix) if path.is_file() else (path, '')\n",
    "#    dirs = glob.glob(f\"{path}{sep}*\")  # similar paths\n",
    "#    matches = [re.search(rf\"%s{sep}(\\d+)\" % path.stem, d) for d in dirs]\n",
    "#    i = [int(m.groups()[0]) for m in matches if m]  # indices\n",
    "#    n = max(i) + 1 if i else 2  # increment number\n",
    "#    path = Path(f\"{path}{sep}{n}{suffix}\")  # increment path\n",
    "#if mkdir:\n",
    "#    path.mkdir(parents=True, exist_ok=True)  # make directory\n",
    "#return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6448bc67",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efca3293-9e5c-4bd8-b309-e50ed6168f0e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# float64 is not always compatible with tiff readers\n",
    "#vdf_stack.change_dtype('float32')\n",
    "#vdf_stack.save(\"output_images/new_dataset.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1bfd84-126e-4f97-bfcd-21ff467ca557",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tifffile\n",
    "vdf_stack.change_dtype('float32')\n",
    "folder_name = \"22-06-27 curls\"\n",
    "os.makedirs(f\"output_images/{folder_name}\", exist_ok=True)\n",
    "vdf_stack.save(f\"output_images/{folder_name}/stack.tif\")\n",
    "vdf_numpy = vdf_stack.data\n",
    "for image, label in zip(vdf_numpy, labels):\n",
    "    print(f\"output_images/{folder_name}/{label}.tif\")\n",
    "    tifffile.imsave(f\"output_images/{folder_name}/{label}.tif\", image, imagej=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef55bcb6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load image stack from a tiff file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217dca9b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "vdf_load = hs.load('virtual diffraction image stack.tif', force_read_resolution=True)\n",
    "\n",
    "# vdf_load.change_dtype('float32')\n",
    "vdf_load.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f9eddd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load stack from Tiff\n",
    "vdf_stack = hs.load('output_images/new_dataset.tif', force_read_resolution=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303b6886",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Inputing images to Segmentation NN\n",
    "## loading network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58c35fd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from delineation.models import build_segmentation_model\n",
    "seg_model = build_segmentation_model(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5618c514",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "if cfg.SETUP.LOCAL:\n",
    "    seg_model.load_state_dict(torch.load(cfg.TEST.MODEL_WEIGHTS, map_location=torch.device('cpu'))['state_dict'])\n",
    "else:\n",
    "    seg_model.load_state_dict(torch.load(cfg.TEST.MODEL_WEIGHTS)['state_dict'])\n",
    "\n",
    "seg_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583a5122",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Converting stack of VDF images to tensors for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8423bf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vdf_stack_tensor = torch.from_numpy(vdf_stack.data/1).float() #65535.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa262494",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    if cfg.SETUP.LOCAL:\n",
    "        # torch.cuda.empty_cache()\n",
    "\n",
    "        _, seg_res1 = seg_model(vdf_stack_tensor.unsqueeze(1))\n",
    "        # _, seg_res2 = seg_model(vdf_stack_tensor[2].unsqueeze(0).unsqueeze(0))\n",
    "#     else:\n",
    "#         torch.cuda.empty_cache()\n",
    "#\n",
    "#         _, seg_res1 = seg_model(vdf_stack_tensor[0].unsqueeze(0).unsqueeze(0).cuda().float())\n",
    "#         _, seg_res2 = seg_model(vdf_stack_tensor[0].unsqueeze(0).unsqueeze(0).cuda().float())\n",
    "seg_map = seg_res1.squeeze().data.cpu().numpy() > 0.05\n",
    "# seg_map2 = seg_res2[0].squeeze().data.cpu().numpy()>0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f59492",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ncols = 3\n",
    "fig, axs = plt.subplots(nrows=seg_map.shape[0]//ncols, ncols= ncols, figsize=cfg.SETUP.PLOT_SIZE)\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.imshow(seg_map[i],cmap = \"gray\" )\n",
    "    ax.set_title(labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125ea84b-29d7-4984-a078-2eeabab8e86b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Topological Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d2d7f6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5d8bf9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "from gtda.images import HeightFiltration, DilationFiltration, ErosionFiltration, RadialFiltration, SignedDistanceFiltration, DensityFiltration\n",
    "from gtda.images import Binarizer, Inverter\n",
    "from gtda.homology import CubicalPersistence\n",
    "from gtda.diagrams import PairwiseDistance\n",
    "from gtda.diagrams import Amplitude, PersistenceEntropy\n",
    "from gtda.diagrams import Filtering\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion, make_union\n",
    "from gtda.plotting import plot_diagram\n",
    "\n",
    "from PIL import Image\n",
    "from labelme import utils\n",
    "from numpy import asarray\n",
    "import matplotlib as mpl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ce81c1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad1743d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_images(images):\n",
    "    if len(images) == 1:\n",
    "        plt.imshow(images[0])\n",
    "    else:\n",
    "        fig, axes = plt.subplots(1, len(images), figsize=(len(images) * 3, 30))\n",
    "        axes = axes.flatten()\n",
    "        cmap = plt.cm.binary\n",
    "        cmap.set_bad('y')\n",
    "        vmin, vmax = np.min(images[images != np.inf]), np.max(images[images != np.inf])\n",
    "\n",
    "        for i in range(len(images)):\n",
    "            axes[i].imshow(images[i], cmap='binary', vmin=vmin, vmax=vmax)\n",
    "            # axes[i].imshow(images[i], vmin=vmin, vmax=vmax)\n",
    "            axes[i].axis('off')  # hide the axes ticks\n",
    "            #axes[i].set_title(names[i], color= 'black', fontsize=12)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_diagrams(X, names=None):\n",
    "    fig, axes = plt.subplots(1, len(X[0]), figsize=(len(X[0]) * 5, 5))\n",
    "    axes = axes.flatten()\n",
    "    colors = {0: 'b', 1: 'r', 2: 'g'}\n",
    "\n",
    "    for i in range(len(X[0])):\n",
    "        diagram = {dimension: X[dimension][i] for dimension in X.keys()}\n",
    "        for dimension in X.keys():\n",
    "            axes[i].plot(diagram[dimension][:, 0], diagram[dimension][:, 1], 'o', color=colors[dimension])\n",
    "            axes[i].plot([0, np.max(X[dimension])], [0, np.max(X[dimension])], color='k')\n",
    "\n",
    "        # axes[i].set_title(names[i], color= 'black', fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_matrices(X):\n",
    "    n_matrices = X.shape[1] // X.shape[0]\n",
    "\n",
    "    iterator = tuple(itertools.product(range(n_matrices), range(1)))\n",
    "    vmin, vmax = np.min(X), np.max(X)\n",
    "    if n_matrices > 1:\n",
    "        figure, axes = plt.subplots(1, n_matrices, figsize=(18, 8))\n",
    "        axes = axes.reshape((1, n_matrices))\n",
    "        for i, j in iterator:\n",
    "            plot = axes[j, i].imshow(X[:, i * X.shape[0]:(i + 1) * X.shape[0]], vmin=vmin, vmax=vmax)\n",
    "\n",
    "    else:\n",
    "        figure, axes = plt.subplots(1, n_matrices, figsize=(6, 9))\n",
    "        plot = axes.imshow(X[:, : 1 * X.shape[0]], vmin=vmin, vmax=vmax)\n",
    "\n",
    "    figure.subplots_adjust(bottom=0.2)\n",
    "    cbar_ax = figure.add_axes([0.3, 0.2, 0.4, 0.03])\n",
    "    norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    colorbar = mpl.colorbar.ColorbarBase(cbar_ax, norm=norm, orientation='horizontal')\n",
    "    colorbar.set_label('Pairwise distances')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def pipeline_steps(filtration_list, homology_dimensions_list):\n",
    "    steps_filtration = [[\n",
    "        ('filtration', filtration)]\n",
    "        for filtration in filtration_list]\n",
    "\n",
    "    steps_persistance = [[\n",
    "        ('filtration', filtration),\n",
    "        ('persistence', CubicalPersistence(homology_dimensions))]\n",
    "        for filtration in filtration_list for homology_dimensions in homology_dimensions_list]\n",
    "\n",
    "    steps_distance = [[\n",
    "        ('filtration', filtration),  #to remove if we use a greyscale image\n",
    "        ('persistence', CubicalPersistence(homology_dimensions)),\n",
    "        ('distance', PairwiseDistance(metric='wasserstein', order=None, metric_params={'p': 2, 'delta': 0.1}))]\n",
    "        for filtration in filtration_list for homology_dimensions in homology_dimensions_list]\n",
    "\n",
    "    return [steps_filtration, steps_persistance, steps_distance]\n",
    "\n",
    "\n",
    "def pipline_processing(images, step_list, mode='distance', plot=False):\n",
    "    pipeline_diag = [(str(i), Pipeline(step_list[i]))\n",
    "                     for i in range(len(step_list))]\n",
    "    feature_union_diag = FeatureUnion(pipeline_diag)\n",
    "    diagrams = feature_union_diag.fit_transform(images)\n",
    "\n",
    "    if plot == True:\n",
    "        if mode == 'filtration':\n",
    "            plot_images(diagrams)\n",
    "\n",
    "\n",
    "        elif mode == 'persistance':\n",
    "            for k in range(diagrams.shape[0]):\n",
    "                fig = plot_diagram(diagrams[k, :, :])\n",
    "                fig.show()\n",
    "\n",
    "        elif mode == 'distance':\n",
    "            plot_matrices(diagrams[:, :, 0])\n",
    "            plot_matrices(diagrams[:, :, 1])\n",
    "\n",
    "    return diagrams\n",
    "\n",
    "\n",
    "def combined_distance(X, weights=None, power=1):\n",
    "    rows, cols = X.shape[0], X.shape[0]\n",
    "    nb_matrix = int(X.shape[1] / X.shape[0])\n",
    "    nb_pipeline = X.shape[-1]\n",
    "    X = np.reshape(X, (rows, nb_matrix, cols, nb_pipeline))\n",
    "\n",
    "    # init the weight to 1 if they are not given\n",
    "    if weights is None:\n",
    "        weights = np.ones(nb_matrix * nb_pipeline)\n",
    "\n",
    "    distance = np.zeros((cols, nb_matrix * nb_pipeline))\n",
    "    for i in range(nb_matrix):\n",
    "        for j in range(nb_pipeline):\n",
    "            ## only take the first row\n",
    "            distance[:, nb_pipeline * i + j] = weights[nb_pipeline * i + j] * (X[:, i, 0, j] ** power)\n",
    "\n",
    "    distance_tot = np.sum(distance, axis=1)\n",
    "    distance_tot = np.reshape(distance_tot, (1, len(distance_tot)))\n",
    "\n",
    "    return distance_tot\n",
    "\n",
    "\n",
    "def plot_combined_distance(X):\n",
    "    figure, axes = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    vmin, vmax = np.min(X), np.max(X)\n",
    "    plot = axes.imshow(X, vmin=vmin, vmax=vmax)\n",
    "    cbar_ax = figure.add_axes([0.3, 0.2, 0.4, 0.03])\n",
    "    norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    colorbar = mpl.colorbar.ColorbarBase(cbar_ax, norm=norm, orientation='horizontal')\n",
    "    colorbar.set_label('Pairwise sum of distances')\n",
    "    axes.set_yticks([])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_distance(X, X_type=\"H0\", dataset=\" \", normalize_per_distance=True, error=None, weight=None):\n",
    "    #normalize\n",
    "    # X_norm = (X-X.min(axis = 0))/(X.max(axis = 0)- X.min(axis = 0))\n",
    "    dilation = [\"Dilation\"]\n",
    "    height = [\"Direction [0, 1]\", \"Direction [0, -1]\", \"Direction [1, 0]\", \"Direction [-1, 0]\"]\n",
    "    density = [\"Density\"]\n",
    "    radial = [\"Position [0.5, 0.5]\",\n",
    "              \"Position [0.5, 0.25]\", \"Position [0.5, 0.75]\",\n",
    "              \"Position [0.25, 0.5]\", \"Position [0.75, 0.5]\",\n",
    "              \"Position [0.25, 0.25]\", \"Position [0.25, 0.75]\",\n",
    "              \"Position [0.75, 0.25]\", \"Position [0.75, 0.75]\"]\n",
    "\n",
    "    ylabel = dilation + density + height + radial\n",
    "    tick_locs = np.arange(len(ylabel))\n",
    "\n",
    "    if normalize_per_distance:\n",
    "        X_norm = X / X.max(axis=0)\n",
    "    else:\n",
    "        X_norm = X / X.max()\n",
    "    if dataset == \"s-error\":\n",
    "        figure, axes = plt.subplots(1, 1, figsize=(3, 11))\n",
    "        plot = axes.imshow(X_norm.T, vmin=0, vmax=1)\n",
    "        axes.set_title(X_type + \" distance : dataset s-error\")\n",
    "    elif dataset == \"BF_CL\":\n",
    "        figure, axes = plt.subplots(1, 1, figsize=(6, 10))\n",
    "        plot = axes.imshow(X_norm.T, vmin=0, vmax=1)\n",
    "        axes.set_title(X_type + \" distance : dataset BF_CL\")\n",
    "    else:\n",
    "        figure, axes = plt.subplots(1, 1, figsize=(int(np.round((X_norm.shape[0]) / 2) - 1), 13))\n",
    "        plot = axes.imshow(X_norm.T, vmin=0, vmax=1)\n",
    "        axes.set_title(X_type + \" distance\")\n",
    "\n",
    "    # axes.set_yticks(tick_locs, legend)\n",
    "\n",
    "    axes.set_xticks(np.arange(X_norm.T.shape[1]))\n",
    "    axes.set_yticks(np.arange(X_norm.T.shape[0]))\n",
    "\n",
    "    axes.set_yticklabels(ylabel)\n",
    "    axes.tick_params(top=True, bottom=False,\n",
    "                     labeltop=True, labelbottom=False)\n",
    "\n",
    "    if error is not None:\n",
    "        ax_top = axes.secondary_xaxis('bottom')\n",
    "        ax_top.set_xticks(np.arange(X_norm.T.shape[1]))\n",
    "        ax_top.set_xlabel('error *10^7', color='r')\n",
    "        ax_top.set_xticklabels(np.round(error, 3), rotation=45)\n",
    "\n",
    "    if weight is not None:\n",
    "        ax_right = axes.secondary_yaxis('right')\n",
    "        ax_right.set_yticks(np.arange(X_norm.T.shape[0]))\n",
    "        ax_right.set_ylabel('weight', color='r')\n",
    "        ax_right.set_yticklabels(np.round(weight.reshape(-1), 3))\n",
    "\n",
    "    # PROBLEM WITH THE DIMENSION OF tHE MATRIX TO PRINT ON THE RIGHT AXES\n",
    "    # if weight is not None :\n",
    "    #   ax_right = axes.twinx()\n",
    "    #   ax_right.set_ylabel('error', color='r')\n",
    "    #   ax_right.set_yticklabels(weight)\n",
    "\n",
    "    figure.subplots_adjust(bottom=0.1)\n",
    "    cbar_ax = figure.add_axes([0.3, 0.2, 0.4, 0.03])\n",
    "    norm = mpl.colors.Normalize(vmin=0, vmax=1)\n",
    "    colorbar = mpl.colorbar.ColorbarBase(cbar_ax, norm=norm, orientation='horizontal')\n",
    "    colorbar.set_label('Pairwise distances')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def label_name():\n",
    "    dilation = [\"Dilation         \"]\n",
    "    height = [\"Direction [0, 1]\", \"Direction [0, -1]\", \"Direction [1, 0]\", \"Direction [-1, 0]\"]\n",
    "    density = [\"Density         \"]\n",
    "    radial = [\"Position [0.5, 0.5]\",\n",
    "              \"Position [0.5, 0.25]\", \"Position [0.5, 0.75]\",\n",
    "              \"Position [0.25, 0.5]\", \"Position [0.75, 0.5]\",\n",
    "              \"Position [0.25, 0.25]\", \"Position [0.25, 0.75]\",\n",
    "              \"Position [0.75, 0.25]\", \"Position [0.75, 0.75]\"]\n",
    "\n",
    "    ylabel = dilation + density + height + radial\n",
    "    return ylabel\n",
    "\n",
    "\n",
    "def get_first_row(X):\n",
    "    rows, cols = X.shape[0], X.shape[0]\n",
    "    nb_matrix = int(X.shape[1] / X.shape[0])\n",
    "    nb_pipeline = X.shape[-1]\n",
    "    X = np.reshape(X, (cols, nb_matrix, rows, nb_pipeline))\n",
    "    distance_H0 = X[1:, :, 0, 0]\n",
    "    distance_H1 = X[1:, :, 0, 1]\n",
    "\n",
    "    return distance_H0, distance_H1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aae37c2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc81815",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This step is only necessary if images are not in memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7db5568",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Make image stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421fb28f-9121-41ab-898e-df0c13e57506",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "folder = 'Dataset_name'\n",
    "ground_truth_number = 1\n",
    "\n",
    "image_name = '35 2BC6 CL=330-30-{}_gt.png'.format(ground_truth_number)\n",
    "path_save = 'Results/dataset_{}-{}/'.format(folder, ground_truth_number)\n",
    "path = 'Dataset2_31072020/'\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "Path(path_save).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e96976-9b01-48e6-b234-3e50d485d730",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# with open(path + '35 2BC6 CL=330-30-1.json') as f:\n",
    "#     data = json.load(f)\n",
    "# imageData = data.get(\"imageData\")\n",
    "# ground_truth = utils.img_b64_to_arr(imageData)\n",
    "\n",
    "ground_truth = Image.open(path + image_name).convert('LA')\n",
    "ground_truth = asarray(ground_truth)[:, :, 0]\n",
    "images = np.expand_dims(ground_truth, axis=0)\n",
    "\n",
    "all_images_path = glob.glob(path + folder + \"/aligned/segmentation_aligned/*.png\")\n",
    "\n",
    "for i, img_path in enumerate(all_images_path):\n",
    "    unique_image = Image.open(img_path).convert('LA')\n",
    "    unique_image = asarray(unique_image)[:, :, 0]\n",
    "    unique_image = np.expand_dims(unique_image, axis=0)\n",
    "\n",
    "    images = np.vstack((images, unique_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57ffec8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "images = seg_map[::3,:,:]\n",
    "print(images.shape)\n",
    "plot_images(images)\n",
    "plot_images(images[:4, 300:500, 400:600])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2834366",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Align Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4e401e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# If we are using the images of the same column, do we still need to align them?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e76a819",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Define Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a37c70",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_center, y_center = int(images.shape[1]/2), int(images.shape[2]/2)\n",
    "\n",
    "direction_list = np.array([ [0, 1], [0, -1], [1, 0], [-1, 0] ])\n",
    "n_neighbors_list = [[2, 4]]\n",
    "# Change this value when calculating 3D\n",
    "homology_dimensions_list = [[0,1]]\n",
    "center_list = np.array([ [x_center, y_center],\n",
    "                         [x_center, int(1/2 * y_center)],\n",
    "                         [x_center, int(3/2 * y_center)],\n",
    "                         [int(1/2 * x_center), y_center],\n",
    "                         [int(3/2 * x_center), y_center],\n",
    "                         [int(1/2 * x_center), int(1/2 * y_center)],\n",
    "                         [int(1/2 * x_center), int(3/2 * y_center)],\n",
    "                         [int(3/2 * x_center), int(1/2 * y_center)],\n",
    "                         [int(3/2 * x_center), int(3/2 * y_center)] ])\n",
    "\n",
    "\n",
    "filtration_list_height = [HeightFiltration(direction=direction)\n",
    "                          for direction in direction_list]\n",
    "\n",
    "filtration_list_dilation = [DilationFiltration()]\n",
    "\n",
    "filtration_list_density = [DensityFiltration()]\n",
    "\n",
    "filtration_list_radial = [RadialFiltration(center=center)\n",
    "                          for center in center_list]\n",
    "\n",
    "# filtration_list_density = [DensityFiltration(n_neighbors=n_neighbors, normalize=False)\n",
    "#                            for n_neighbors in n_neighbors_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a308f02",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generic_filtration(filtration_list, homology_dimensions_list, plot = False):\n",
    "    steps = pipeline_steps(filtration_list, homology_dimensions_list)\n",
    "    # steps_filtration = steps[0]\n",
    "    # steps_persistance = steps[1]\n",
    "    steps_distance = steps[2]\n",
    "\n",
    "    # _ = pipline_processing(images, steps_filtration_radial, mode='filtration', plot=plot)\n",
    "    # _ = pipline_processing(images, steps_persistance_radial, mode='persistance', plot=plot)\n",
    "    diagrams_distance = pipline_processing(images, steps_distance, mode='distance', plot=plot)\n",
    "    distance = combined_distance(diagrams_distance, weights = None, power = 1)\n",
    "    plot_combined_distance(distance)\n",
    "    return diagrams_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28626ec6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Filtrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719cb168",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Dilation\n",
    "diagrams_distance = generic_filtration(filtration_list_dilation, homology_dimensions_list, plot = False)\n",
    "np.savez(path_save + \"diagrams_distance_dilation.npz\", diagrams_distance_dilation = diagrams_distance)\n",
    "# Density\n",
    "diagrams_distance = generic_filtration(filtration_list_density, homology_dimensions_list, plot = False)\n",
    "np.savez(path_save + \"diagrams_distance_density.npz\", diagrams_distance_density = diagrams_distance)\n",
    "# Height\n",
    "diagrams_distance = generic_filtration(filtration_list_height, homology_dimensions_list, plot = False)\n",
    "np.savez(path_save + \"diagrams_distance_height.npz\", diagrams_distance_height = diagrams_distance)\n",
    "# Radial\n",
    "diagrams_distance = generic_filtration(filtration_list_radial, homology_dimensions_list, plot = False)\n",
    "np.savez(path_save + \"diagrams_distance_radial.npz\", diagrams_distance_radial = diagrams_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13351fb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load distances from files ( to avoid repeating previous calculations )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b93f52e-9544-4b92-bd4b-cc49a3a65d42",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = np.load(path_save + \"diagrams_distance_dilation.npz\")\n",
    "diagrams_distance_dilation = data['diagrams_distance_dilation']\n",
    "\n",
    "data = np.load(path_save + \"diagrams_distance_radial.npz\")\n",
    "diagrams_distance_radial = data['diagrams_distance_radial']\n",
    "\n",
    "data = np.load(path_save + \"diagrams_distance_height.npz\")\n",
    "diagrams_distance_height = data['diagrams_distance_height']\n",
    "\n",
    "data = np.load(path_save + \"diagrams_distance_density.npz\")\n",
    "diagrams_distance_density = data['diagrams_distance_density']\n",
    "\n",
    "all_distance = [diagrams_distance_dilation, diagrams_distance_density,\n",
    "                diagrams_distance_height, diagrams_distance_radial]\n",
    "\n",
    "distance_H0 = np.array([])\n",
    "distance_H1 = np.array([])\n",
    "\n",
    "\n",
    "for i, dist in enumerate(all_distance) :\n",
    "    tmp_H0, tmp_H1 = get_first_row(dist)\n",
    "    distance_H0 = np.hstack([distance_H0, tmp_H0]) if distance_H0.size else tmp_H0\n",
    "    distance_H1 = np.hstack([distance_H1, tmp_H1]) if distance_H1.size else tmp_H1\n",
    "\n",
    "# distance = combined_distance(diagrams_distance_radial, weights = None, power = 1)\n",
    "# distance_H0, distance_H1 = get_first_row(diagrams_distance_radial)\n",
    "plot_distance(distance_H0, \"H0\", folder)\n",
    "plot_distance(distance_H1, \"H1\", folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d9994a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Weights optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a19be70",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize, Bounds\n",
    "\n",
    "def compute_best_algo(distance_H0, distance_H1=None, type=\"stack\"):\n",
    "    if type == \"stack_3d\":\n",
    "        all_distance = np.dstack((distance_H0, distance_H1))\n",
    "        all_distance = np.swapaxes(all_distance, 0, 1)\n",
    "    elif type == \"stack\":\n",
    "        all_distance = np.hstack((distance_H0, distance_H1))\n",
    "        all_distance = np.swapaxes(all_distance, 0, 1)\n",
    "    elif type == \"single\" or \"H0\" or \"H1\":\n",
    "        all_distance = np.swapaxes(distance_H0, 0, 1)\n",
    "    else:\n",
    "        raise NameError('Wrong type')\n",
    "\n",
    "    print(str(all_distance.shape))\n",
    "    weights_dataset = optimization(all_distance)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    distance_label = label_name()\n",
    "    #in this case there are twice more weights\n",
    "    if type == \"stack\":\n",
    "        index_middle = len(distance_label)\n",
    "\n",
    "        print(\"weights for H0\\n\")\n",
    "        for i, (weight, label) in enumerate(zip(weights_dataset[:index_middle], distance_label)):\n",
    "            print(\"%s\\t weight  %.3f\" % (label, weight))\n",
    "        print(\"\\nweights for H1\\n\")\n",
    "        for i, (weight, label) in enumerate(zip(weights_dataset[index_middle:], distance_label)):\n",
    "            print(\"%s\\t weight  %.3f\" % (label, weight))\n",
    "\n",
    "    else:\n",
    "        if type == \"H0\" or \"H1\":\n",
    "            print(\"weights for %s\\n\" % type)\n",
    "        else:\n",
    "            print(\"weights for H0 and H1\\n\")\n",
    "        for i, (weight, label) in enumerate(zip(weights_dataset, distance_label)):\n",
    "            print(\"%s\\t weight  %.3f\" % (label, weight))\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    #best algorithm\n",
    "    if type == \"stack_3d\":\n",
    "        weights_dataset = weights_dataset.reshape(-1, 1, 1)\n",
    "        error = weights_dataset * all_distance\n",
    "        total_error = np.sum(np.sum(error, axis=0), axis=-1) * 1e-7\n",
    "        partial_error = np.sum(error, axis=0) * 1e-7\n",
    "    elif type == \"stack\":\n",
    "        weights_dataset = weights_dataset.reshape(-1, 1)\n",
    "        error = weights_dataset * all_distance\n",
    "        total_error = np.sum(error, axis=0) * 1e-7\n",
    "        mid_index = np.int(len(weights_dataset) / 2)\n",
    "        partial_error = np.vstack((np.sum(error[mid_index:], axis=0) * 1e-7,\n",
    "                                   np.sum(error[:mid_index], axis=0) * 1e-7))\n",
    "        partial_error = partial_error.T\n",
    "\n",
    "    else:\n",
    "        weights_dataset = weights_dataset.reshape(-1, 1)\n",
    "        error = weights_dataset * all_distance\n",
    "        total_error = np.sum(error, axis=0) * 1e-7\n",
    "        partial_error = 0\n",
    "\n",
    "    # total_error\n",
    "    index = np.argsort(total_error)\n",
    "    print(\"Sorted from best to worst\\n\")\n",
    "    for i in range(len(index)):\n",
    "        print(\"Algorithm : %d\\t error : %.3f\" % (index[i], total_error[index[i]]))\n",
    "\n",
    "    return all_distance, weights_dataset, index, total_error, partial_error\n",
    "\n",
    "\n",
    "def optimization(all_distance):\n",
    "    x0 = np.repeat(1, all_distance.shape[0])\n",
    "    cons = {'type': 'eq', 'fun': lambda x0: 1.0 - np.prod(x0)}\n",
    "    bounds = Bounds(0, np.Inf)\n",
    "    # if the distance of H0 and H1 are stacked in the 3rd dimension --> weights of a distance is the same for H0 and H1\n",
    "    if len(all_distance.shape) == 3:\n",
    "        result = minimize(f_stack_3d, x0, args=all_distance, method='trust-constr', bounds=bounds, constraints=cons)\n",
    "    else:\n",
    "        result = minimize(f, x0, args=all_distance, method='trust-constr', bounds=bounds, constraints=cons)\n",
    "    weights = result.x\n",
    "    error = result.fun\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "def f(params, all_distance):\n",
    "    weights = params.reshape(-1, 1)\n",
    "    # print(\"all_distance \" + str(all_distance.shape))\n",
    "    # print(\"weights \" + str(weights.shape))\n",
    "    error = weights * all_distance\n",
    "    total_error = np.sum(error, axis=-1)\n",
    "    total_error = -1 * np.sum(total_error)\n",
    "    # print(str(total_error))\n",
    "    return total_error\n",
    "\n",
    "\n",
    "def f_stack_3d(params, all_distance):\n",
    "    weights = params.reshape(-1, 1, 1)\n",
    "    # print(\"3d, all_distance \" + str(all_distance.shape))\n",
    "    # print(\"weights \" + str(weights.shape))\n",
    "    error = weights * all_distance\n",
    "    total_error = np.sum(np.sum(error, axis=1), axis=-1)\n",
    "    total_error = -1 * np.sum(total_error)\n",
    "    # print(str(total_error))\n",
    "    return total_error\n",
    "\n",
    "\n",
    "def constraint(params):\n",
    "    sum_element = 1\n",
    "    sum = np.sum(params)\n",
    "    return sum - sum_element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05f8563",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### best algorithm of dataset ***BF_CL***\n",
    "\n",
    "- *H0* and *H1* are stacked in the 3rd dimension\n",
    "- weights for each distance are equal for *H0* and *H1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b47052",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "all_distance, weight, index, total_error, partial_error = compute_best_algo(distance_H0, distance_H1, type=\"stack_3d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f07fdac",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_distance(distance_H0, X_type=\"H0\", error=partial_error[:, 0], weight=weight)\n",
    "plot_distance(distance_H1, X_type=\"H1\", error=partial_error[:, 1], weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9809a0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_combined_distance(total_error, X_type=\"H0 and H1 combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1114c69",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# save sorted algortihm and weights\n",
    "# np.savez(path_save + \"weights.npz\", weights = weights_dataset)\n",
    "# np.savez(path_save + \"index_algorithm_sorted.npz\", index_algorithm_sorted = index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb42de40",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### best algorithm of dataset ***BF_CL***\n",
    "- * H0 * and *H1 * are\n",
    "stacked in the\n",
    "2\n",
    "nd\n",
    "dimension\n",
    "- weights\n",
    "for each distance are different for * H0 * and * H1 * but the sum of all the weights is 1\n",
    "all_distance, weight, index, total_error, partial_error = compute_best_algo(distance_H0, distance_H1, type=\"stack\")\n",
    "mid_index = np.int(len(weight) / 2)\n",
    "plot_distance(distance_H0, X_type=\"H0\", error=partial_error[:, 0], weight=weight[:mid_index])\n",
    "plot_distance(distance_H1, X_type=\"H1\", error=partial_error[:, 1], weight=weight[mid_index:])\n",
    "plot_combined_distance(total_error, X_type=\"H0 and H1 combined\")\n",
    "### best algorithm of dataset ***BF_CL***\n",
    "- * H0 * and *H1 * are\n",
    "computed\n",
    "separately\n",
    "- sum\n",
    "of\n",
    "weights\n",
    "for *H0 * is equal to 1\n",
    "- sum\n",
    "of\n",
    "weights\n",
    "for *H1 * is equal to 1\n",
    "\n",
    "all_distance_H0, weight_H0, index_H0, total_error_H0, _ = compute_best_algo(distance_H0, type=\"H0\")\n",
    "all_distance_H1, weight_H1, index_H1, total_error_H1, _ = compute_best_algo(distance_H1, type=\"H1\")\n",
    "plot_distance(distance_H0, X_type=\"H0\", error=total_error_H0, weight=weight_H0)\n",
    "plot_distance(distance_H1, X_type=\"H1\", error=total_error_H1, weight=weight_H1)\n",
    "plot_combined_distance(total_error_H0 + total_error_H1, X_type=\"H0 and H1 combined\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b5ba41a297f25b4d88f899315a8935b86f3b5ccebce5ac12a2710467a1222904"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
